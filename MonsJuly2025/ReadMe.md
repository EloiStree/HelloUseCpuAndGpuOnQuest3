

# Jeudi

Intention: Vous apprendre a configurer un project XR.

**Matin :**

- Créer un projet Unity URP
- Ajouter OpenXR
- Ajouter le SDK Meta
- Ajouter un objet 3D
- Ajouter un script XRTK
- Dernière vérification
- Build sur le Quest 3

**Après-midi :**

- [ ] Ajouter un drone Tello
- [ ] Ajouter un Input Action
- [ ] Relier les deux via le clavier
- [ ] Ajouter le système d’Input OpenXR
- [ ] Build and hope
- [ ] Installer Link sur le PC
- [ ] Vérifier si les PC supportent Link
- [ ] Créer un circuit
- [ ] Jouer a [XRTK](www.youtube.com/watch?v=eDicfcAgJB4&pp=0gcJCb4JAYcqIYzv)

---

# Vendredi

Intention: Vous apprendre a utiliser de Compute Shader pour la XR

Reproduire cette application perdu dans le temps: [Reality Hacker VR](https://reality-hacker-vr.en.softonic.com/android)
[<img width="1901" height="995" alt="image" src="https://github.com/user-attachments/assets/d379e7ed-027f-48e4-9bb5-0e97162601aa" />](https://youtu.be/JnZOoryLwAI
)  
https://youtu.be/JnZOoryLwAI  

**Matin :**

- [ ] Cloner et configurer le projet de passthrough de Meta

  - [ ] [https://github.com/meta-quest/Meta-Passthrough-Camera-API-Samples](https://github.com/meta-quest/Meta-Passthrough-Camera-API-Samples)
- [ ] Le builder et l’essayer
- [ ] Extraire la `WebCamTexture` de la caméra
- [ ] Prendre des photos au format TGA depuis la caméra
- [ ] Récupérer les photos avec SideQuest
- [ ] *Pause*
- [ ] Transformer une `Texture2D` en `RenderTexture`
- [ ] Inverser deux couleurs avec un Compute Shader
- [ ] Pour le fun : séparer les canaux rouge, vert et bleu
- [ ] Appliquer les nouvelles textures sur des cubes

**Après-midi :**

- [ ] Introduction au hackathon :
  - [ ] [https://xrbootcamp.typeform.com/xraihack2025](https://xrbootcamp.typeform.com/xraihack2025)
- [ ] Isoler la couleur orange avec un code traditionnel
  - [ ] Observer le temps d’exécution
- [ ] Essayer avec Shader Graph :
  - [ ] Récupérer la texture
  - [ ] Observer le temps d’exécution
- [ ] Essayer avec un Compute Shader
  - [ ] Observer le temps d’exécution
- [ ] Essayer avec le Job System pour comparaison
  - [ ] Observer le temps d’exécution
- [ ] **Exercice :**
  - [ ] Trouver les quatre coins d’un post-it

---

**Packages utiles :**

- [ ] [Play With Camera API](https://github.com/EloiStree/2025_06_13_PlayWithCameraAPI.git)
- [ ] [Watch Execute Time](https://github.com/EloiStree/2024_04_18_WatchExecuteTime.git)
- [ ] [Texture2D Toolbox](https://github.com/EloiStree/2025_06_13_ToolboxTexture2D)



Link:
Les yeux du Daltonisme: https://lesyeuxdudaltonisme.fr/les-types-de-daltonisme/

Creer un Gardiant de couleur sans Texture2D dans Unity
https://chatgpt.com/share/68760590-a938-800e-b5ba-a99259b6d154


[<img width="600" height="670" alt="image" src="https://github.com/user-attachments/assets/2ab051bc-40d9-457d-8469-5502cbcee609" />
](https://scipython.com/blog/converting-a-spectrum-to-a-colour/)  
https://scipython.com/blog/converting-a-spectrum-to-a-colour/  
Maybe:https://chatgpt.com/share/687609af-98ec-800e-8f90-78556223c6e3



https://gitlab.com/eloistree/2018_06_01_MeshToVoxel



Frida Wall
[<img width="1260" height="558" alt="image" src="https://github.com/user-attachments/assets/01360622-d91a-421d-bb40-b6ec3a23db2c" />
](https://youtu.be/pVxhmuf2IeA?t=141)  
https://youtu.be/pVxhmuf2IeA?t=141  
https://youtu.be/rso9u7mkP68?t=9  

[<img width="1258" height="558" alt="image" src="https://github.com/user-attachments/assets/473796fd-8d9a-4040-8628-4852884a6c2c" />
<img width="1156" height="623" alt="image" src="https://github.com/user-attachments/assets/99df6a1e-7482-4955-92a3-69700520fcde" />
](https://youtu.be/gT3I8qI2y4E?t=998)  
https://youtu.be/gT3I8qI2y4E?t=998



Replicator
[<img width="1225" height="586" alt="image" src="https://github.com/user-attachments/assets/ec412c3d-c2f8-4c5f-8171-ce402613e3c5" />
](https://youtu.be/BPbTssjNvzs?t=16)
https://youtu.be/BPbTssjNvzs?t=16


Il n y a que trois meshs ici:
[<img width="1374" height="610" alt="image" src="https://github.com/user-attachments/assets/9c37f244-bd94-4004-952e-6bcd62c9ee27" />](https://youtu.be/f21l7T1aFu0?t=14)



[<img width="598" height="647" alt="image" src="https://github.com/user-attachments/assets/d64c9a6b-f153-44b0-9ea1-8b0a3737dfb8" />](https://people.eecs.berkeley.edu/~sequin/CS184/TOPICS/ColorSpaces/Color_0.html)

[<img width="966" height="425" alt="image" src="https://github.com/user-attachments/assets/35ac5bf0-bfec-45b5-b1e5-372a9d40b6e4" />](https://people.eecs.berkeley.edu/~sequin/CS184/TOPICS/ColorSpaces/Color_0.html)  
https://people.eecs.berkeley.edu/~sequin/CS184/TOPICS/ColorSpaces/Color_0.html



Snake https://youtu.be/VphtcDhHj40?t=13
Cow ; No Read https://youtu.be/VphtcDhHj40?t=30
Bird + ulta violet = https://youtu.be/VphtcDhHj40?t=110

Fish = less red https://youtu.be/VphtcDhHj40?t=84
Shark = Grayscale https://youtu.be/VphtcDhHj40?t=94


Bee : red is a dark blue
https://youtu.be/VphtcDhHj40?t=159

Car: Not red or green but have some borwn yellow  https://youtu.be/VphtcDhHj40?t=177
Better grain intensity

Dog: Cant see red or orange but can see blue and violet with good gray
https://youtu.be/VphtcDhHj40?t=201

Frog only see what is moving
https://youtu.be/VphtcDhHj40?t=220
